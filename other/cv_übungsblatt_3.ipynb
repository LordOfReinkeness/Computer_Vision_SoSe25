{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "517e1333",
   "metadata": {
    "id": "517e1333"
   },
   "source": [
    "### Computer Vision: Übungsblatt 3 <br> IMAGE STITCHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911e5cee",
   "metadata": {
    "id": "911e5cee"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87af2da2",
   "metadata": {
    "id": "87af2da2"
   },
   "source": [
    "#### a. Erweitern Sie Ihre Python-Funktion zur projektiven Entzerrung so, daß sie mehr als 4 Passpunkte verarbeiten kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3263126f",
   "metadata": {
    "id": "3263126f"
   },
   "outputs": [],
   "source": [
    "def projective_transform(source_image, source_points, target_shape, target_points):\n",
    "    H = compute_homography_least_squares(source_points, target_points)\n",
    "    output_image = warp_projective_indirect(source_image, H, target_shape)\n",
    "    return output_image\n",
    "\n",
    "def compute_homography_least_squares(source_points, target_points):\n",
    "    \"\"\"\n",
    "    Computes the homography matrix H using the DLT algorithm and\n",
    "    least-squares with pseudo-inverse for N >= 4 points.\n",
    "\n",
    "    Args:\n",
    "        source_points (np.ndarray): An Nx2 array of (x', y') coordinates.\n",
    "        target_points (np.ndarray): An Nx2 array of (x, y) coordinates.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The 3x3 homography matrix H, or None if input is invalid.\n",
    "    \"\"\"\n",
    "    n_points = source_points.shape[0]\n",
    "    if n_points < 4 or source_points.shape != target_points.shape:\n",
    "        print(\"Error: At least 4 point pairs are required and shapes must match.\")\n",
    "        return None\n",
    "\n",
    "    # Build the M matrix and b vector\n",
    "    M = []\n",
    "    b = []\n",
    "    for i in range(n_points):\n",
    "        x_prime, y_prime = source_points[i]\n",
    "        x, y = target_points[i]\n",
    "\n",
    "        M.append([x_prime, y_prime, 1, 0, 0, 0, -x * x_prime, -x * y_prime])\n",
    "        M.append([0, 0, 0, x_prime, y_prime, 1, -y * x_prime, -y * y_prime])\n",
    "        b.append(x)\n",
    "        b.append(y)\n",
    "\n",
    "    M = np.array(M) # Shape (2N, 8)\n",
    "    b = np.array(b) # Shape (2N,)\n",
    "\n",
    "    # Solve Ma = b using the pseudo-inverse\n",
    "    try:\n",
    "        M_pinv = np.linalg.pinv(M)\n",
    "        a = M_pinv @ b\n",
    "    except np.linalg.LinAlgError:\n",
    "        print(\"Error: Could not compute pseudo-inverse or solve the system.\")\n",
    "        return None\n",
    "\n",
    "    # Reshape 'a' (which has 8 elements) into the 3x3 H matrix\n",
    "    H = np.array([\n",
    "        [a[0], a[1], a[2]],\n",
    "        [a[3], a[4], a[5]],\n",
    "        [a[6], a[7], 1.0]  # Add h33 = 1\n",
    "    ])\n",
    "\n",
    "    return H\n",
    "\n",
    "# --- Example Usage ---\n",
    "# Define more than 4 source and target points\n",
    "# source_pts = np.array([[0, 0], [100, 0], [100, 100], [0, 100], [50, 50]])\n",
    "# target_pts = np.array([[10, 10], [110, 5], [115, 110], [5, 105], [60, 60]])\n",
    "#\n",
    "# H_matrix = compute_homography_least_squares(source_pts, target_pts)\n",
    "#\n",
    "# if H_matrix is not None:\n",
    "#     print(\"Computed Homography Matrix H:\")\n",
    "#     print(H_matrix)\n",
    "\n",
    "\n",
    "def warp_projective_indirect(source_image, H_matrix, output_shape):\n",
    "    \"\"\"\n",
    "    Warps a source image using a homography H via indirect mapping\n",
    "    with nearest neighbor interpolation.\n",
    "\n",
    "    Args:\n",
    "        source_image (np.ndarray): The input image (H x W x C or H x W).\n",
    "        H_matrix (np.ndarray): The 3x3 homography matrix.\n",
    "        output_shape (tuple): A tuple (height, width) for the output image.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The warped output image.\n",
    "    \"\"\"\n",
    "    source_height, source_width = source_image.shape[:2]\n",
    "    output_height, output_width = output_shape\n",
    "\n",
    "    # --- Step 1: Invert the Homography Matrix ---\n",
    "    # We need H_inv to map from target back to source.\n",
    "    try:\n",
    "        H_inv = np.linalg.inv(H_matrix)\n",
    "    except np.linalg.LinAlgError:\n",
    "        print(\"Error: Homography matrix is not invertible.\")\n",
    "        return None\n",
    "\n",
    "    # --- Step 2: Create the Output Image ---\n",
    "    # Determine if it's color or grayscale\n",
    "    if len(source_image.shape) == 3:\n",
    "        output_image = np.zeros((output_height, output_width, source_image.shape[2]), dtype=source_image.dtype)\n",
    "    else:\n",
    "        output_image = np.zeros((output_height, output_width), dtype=source_image.dtype)\n",
    "\n",
    "    # --- Step 3: Iterate Through Target Pixels (Indirect Mapping) ---\n",
    "    for y_target in range(output_height):\n",
    "        for x_target in range(output_width):\n",
    "\n",
    "            # Create homogeneous coordinate for the target pixel\n",
    "            target_coords_h = np.array([x_target, y_target, 1.0])\n",
    "\n",
    "            # --- Step 4: Map Target to Source using H_inv ---\n",
    "            source_coords_h = H_inv @ target_coords_h\n",
    "\n",
    "            # --- Step 5: Convert back to Inhomogeneous Coordinates ---\n",
    "            # Avoid division by zero or very small numbers\n",
    "            w = source_coords_h[2]\n",
    "            if abs(w) < 1e-9:\n",
    "                continue\n",
    "\n",
    "            x_source = source_coords_h[0] / w\n",
    "            y_source = source_coords_h[1] / w\n",
    "\n",
    "            # --- Step 6: Interpolate (Nearest Neighbor) ---\n",
    "            x_s_int = int(round(x_source))\n",
    "            y_s_int = int(round(y_source))\n",
    "\n",
    "            # --- Step 7: Check Bounds and Assign Pixel Value ---\n",
    "            if 0 <= x_s_int < source_width and 0 <= y_s_int < source_height:\n",
    "                output_image[y_target, x_target] = source_image[y_s_int, x_s_int]\n",
    "\n",
    "    return output_image\n",
    "\n",
    "# --- Example Usage (requires an image and H) ---\n",
    "# H = compute_homography_least_squares(source_pts, target_pts)\n",
    "# try:\n",
    "#     img = np.array(Image.open('your_image.jpg'))\n",
    "# except FileNotFoundError:\n",
    "#     print(\"Please replace 'your_image.jpg' with a real image file.\")\n",
    "#     img = None\n",
    "#\n",
    "# if H is not None and img is not None:\n",
    "#     warped_img = warp_projective_indirect(img, H, (600, 800))\n",
    "#     if warped_img is not None:\n",
    "#         # Display or save the warped_img\n",
    "#         # (e.g., using matplotlib or Pillow)\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8390991e",
   "metadata": {
    "id": "8390991e",
    "outputId": "bd11b3dd-06e0-4a97-eae4-dd9c74e39367"
   },
   "outputs": [],
   "source": [
    "image_path = './../übungsblatt_2/schraegbild_tempelhof.jpg'\n",
    "\n",
    "image = io.imread(image_path) # uint8 -> 0 - 255\n",
    "print(type(image))\n",
    "print(image.dtype)\n",
    "\n",
    "image = image.astype(float)\n",
    "# scale from 0 to 1\n",
    "image /= 255.0\n",
    "\n",
    "\n",
    "# Passpunkte\n",
    "source_points_bi = np.array([\n",
    "    [347, 328],  # b1 (x1, y1) - oben-links\n",
    "    [537, 328],  # b2 (x2, y2) - oben-rechts\n",
    "    [852, 538],  # b3 (x3, y3) - unten-rechts\n",
    "    [266, 547]    # b4 (x4, y4) - unten-links\n",
    "], dtype=float)\n",
    "\n",
    "target_width = 400\n",
    "target_height = 600\n",
    "\n",
    "target_points_oi = np.array([\n",
    "    [0, 0],\n",
    "    [target_width - 1, 0],\n",
    "    [target_width - 1, target_height - 1],\n",
    "    [0, target_height - 1]\n",
    "], dtype=float)\n",
    "\n",
    "\n",
    "target_shape = (600, 400)\n",
    "\n",
    "image = projective_transform(image, source_points_bi, target_shape, target_points_oi)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04a6853",
   "metadata": {
    "id": "c04a6853",
    "outputId": "8fd07473-9e4a-4cbc-d1d5-a6cf6193612f"
   },
   "outputs": [],
   "source": [
    "image_path = './../übungsblatt_2/schraegbild_tempelhof.jpg'\n",
    "\n",
    "image = io.imread(image_path) # uint8 -> 0 - 255\n",
    "print(type(image))\n",
    "print(image.dtype)\n",
    "\n",
    "image = image.astype(float)\n",
    "# scale from 0 to 1\n",
    "image /= 255.0\n",
    "\n",
    "# Passpunkte im Bild (source image coordinates)\n",
    "source_points_bi = np.array([\n",
    "    [347, 328],  # b1 - oben-links\n",
    "    [537, 328],  # b2 - oben-rechts\n",
    "    [820, 335],  # b3 - unten-rechts\n",
    "    [887, 480],  # b4 - unten-links\n",
    "    [440, 430],  # b5 - Mitte oben (zwischen b1 und b2)\n",
    "    [560, 500],  # b6 - Mitte unten (zwischen b2 und b3)\n",
    "], dtype=float)\n",
    "\n",
    "# Zielkoordinaten im entzerrten Bild (target plane coordinates)\n",
    "target_width = 800\n",
    "target_height = 400\n",
    "\n",
    "t_p = np.array([\n",
    "    [0, 0],\n",
    "    [int(target_width /2), 0],\n",
    "    [target_width - 1, 0],\n",
    "    [0, target_height - 1],\n",
    "    [int(target_width / 2), int(target_height / 2)],\n",
    "    [target_width - 1, target_height - 1],\n",
    "\n",
    "], dtype=float)\n",
    "\n",
    "target_points_oi = np.array([\n",
    "    [0, 0],                                 # o1 - oben-links\n",
    "    [target_width - 1, 0],                  # o2 - oben-rechts\n",
    "    [0, 800],\n",
    "    [10, 2],\n",
    "    [target_width // 2, target_height // 3],       # o5 - Mitte oben\n",
    "    [3 * target_width // 4, 2 * target_height // 3]  # o6 - Mitte unten\n",
    "], dtype=float)\n",
    "\n",
    "\n",
    "target_shape = (600, 400)\n",
    "\n",
    "image = projective_transform(image, source_points_bi, target_shape, t_p)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7abebd7",
   "metadata": {
    "id": "d7abebd7"
   },
   "source": [
    "#### b. Passpunkte und Weltkoordinaten Häuserfront"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4640167",
   "metadata": {
    "id": "e4640167"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_closed_polygon(points, color='blue', marker='o', label_prefix='P', show_labels=True, line_style='-', line_width=1):\n",
    "    \"\"\"\n",
    "    Plottet eine Reihe von Punkten und verbindet sie sequentiell\n",
    "    zu einem geschlossenen Polygon mit matplotlib.\n",
    "\n",
    "    Args:\n",
    "        points (np.ndarray): Ein Nx2 NumPy-Array mit den (x, y)-Koordinaten der Punkte.\n",
    "        color (str): Die Farbe für die Punkte und Linien.\n",
    "        marker (str): Der Marker-Stil für die Punkte (z.B. 'o', 'x', 's').\n",
    "        label_prefix (str): Das Präfix für die Beschriftung der Punkte (z.B. 'b' oder 'o').\n",
    "        show_labels (bool): Wenn True, werden die Punkte beschriftet.\n",
    "        line_style (str): Der Linienstil (z.B. '-', '--', ':').\n",
    "        line_width (float): Die Dicke der Linien.\n",
    "    \"\"\"\n",
    "    # Überprüfen, ob genügend Punkte vorhanden sind\n",
    "    if points is None or not isinstance(points, np.ndarray) or points.ndim != 2 or points.shape[1] != 2:\n",
    "        print(\"Fehler: 'points' muss ein Nx2 NumPy-Array sein.\")\n",
    "        return\n",
    "\n",
    "    num_points = points.shape[0]\n",
    "    if num_points < 3:\n",
    "        print(\"Warnung: Es werden mindestens 3 Punkte benötigt, um ein sinnvolles Polygon zu zeichnen.\")\n",
    "        # Wenn weniger als 3 Punkte, nur Punkte zeichnen\n",
    "        plt.scatter(points[:, 0], points[:, 1], s=50, c=color, marker=marker, label=f'Punkte {label_prefix}')\n",
    "        if show_labels:\n",
    "            for i, (x, y) in enumerate(points):\n",
    "                plt.text(x + 15, y - 15, f'${label_prefix}_{{{i+1}}}$', color=color, fontsize=12)\n",
    "        return\n",
    "\n",
    "    # 1. Punkte plotten (wie im Beispiel)\n",
    "    plt.scatter(points[:, 0], points[:, 1], s=50, c=color, marker=marker, label=f'Passpunkte {label_prefix}')\n",
    "\n",
    "    # 2. Text-Labels hinzufügen (wie im Beispiel)\n",
    "    if show_labels:\n",
    "        for i, (x, y) in enumerate(points):\n",
    "            # Formatiert als LaTeX-String, z.B. $b_1$\n",
    "            plt.text(x + 15, y - 15, f'${label_prefix}_{{{i+1}}}$', color=color, fontsize=12)\n",
    "\n",
    "    # 3. Punkte für die Linien vorbereiten: Ersten Punkt am Ende anfügen\n",
    "    x_lines = np.append(points[:, 0], points[0, 0])\n",
    "    y_lines = np.append(points[:, 1], points[0, 1])\n",
    "\n",
    "    # 4. Linien plotten (sequentiell + letzte zur ersten)\n",
    "    plt.plot(x_lines, y_lines, color=color, linestyle=line_style, linewidth=line_width)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c1ac74",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "d8c1ac74",
    "outputId": "cf6d7c40-b182-42d7-9138-7cdbdcf6476d"
   },
   "outputs": [],
   "source": [
    "image_all_path = './Fassade_ganz.jpg'\n",
    "image_all = io.imread(image_all_path) # uint8 -> 0 - 255\n",
    "\n",
    "image_all = image_all.astype(float)\n",
    "# scale from 0 to 1\n",
    "image_all /= 255.0\n",
    "\n",
    "image_one_path = './Fassade_1.jpg'\n",
    "\n",
    "image_one = io.imread(image_one_path) # uint8 -> 0 - 255\n",
    "\n",
    "image_one = image_one.astype(float)\n",
    "# scale from 0 to 1\n",
    "image_one /= 255.0\n",
    "\n",
    "target_points_1 = np.array([\n",
    "[3820, 1780], [3380, 1820], [3330, 1140], [3080, 1400],[3610, 1790], [4260, 1520], [3460, 1500], [3110, 1500], [4450, 1810], [2740,1140],\n",
    "[4140, 2260],\n",
    "[4350, 1850]], dtype=float)\n",
    "\n",
    "\n",
    "source_points_1 = np.array([\n",
    "   [1630, 1220], [340, 1350], [1180, 220], [380, 680],[620, 1280], [1410, 610], [740, 790], [250, 840], [2130, 1180], [320, 360],\n",
    "   [410, 2190],\n",
    "   [1760, 1290]], dtype=float)\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.imshow(image_one)\n",
    "plot_closed_polygon(source_points_1, color='red', label_prefix='b', show_labels=True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "image_two_path = './Fassade_2.jpg'\n",
    "\n",
    "image_two = io.imread(image_two_path) # uint8 -> 0 - 255\n",
    "image_two = image_two.astype(float)\n",
    "image_two /= 255.0\n",
    "\n",
    "target_points_2 = np.array([[3400, 1820], [3330, 1140], [3080, 1400],[2710, 1530], [2500, 1520], [2890, 2130]], dtype=float)\n",
    "source_points_2 = np.array([[1800, 1840], [1450, 810], [1200, 1050], [580, 1120], [100, 1030], [910, 2380]], dtype=float)\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.imshow(image_two)\n",
    "plot_closed_polygon(source_points_2, color='red', label_prefix='b', show_labels=True)\n",
    "plt.show()\n",
    "\n",
    "image_three_path = './Fassade_3.jpg'\n",
    "\n",
    "image_three = io.imread(image_three_path) # uint8 -> 0 - 255\n",
    "\n",
    "image_three = image_three.astype(float)\n",
    "# scale from 0 to 1\n",
    "image_three /= 255.0\n",
    "\n",
    "target_points_3 = np.array([[3080, 1400],[2710, 1530], [1990, 1070], [1990, 2160], [1260, 1760], [2500, 1520], [2890, 2130],\n",
    "                            [2140, 1320]], dtype=float)\n",
    "source_points_3 = np.array([[3280, 630], [2440, 880], [1440, 210], [720, 2160],[310, 1470], [2020, 890], [2640, 2130],\n",
    "                            [1320, 470]], dtype=float)\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.imshow(image_three)\n",
    "plot_closed_polygon(source_points_3, color='red', label_prefix='b', show_labels=True)\n",
    "plt.show()\n",
    "\n",
    "image_four_path = './Fassade_4.jpg'\n",
    "image_four = io.imread(image_four_path) # uint8 -> 0 - 255\n",
    "image_four = image_four.astype(float)\n",
    "# scale from 0 to 1\n",
    "image_four /= 255.0\n",
    "print('begin 1')\n",
    "target_points_4 = np.array([[1990, 2160], [1260, 1760], [680, 1760], [1960, 1590], [1370, 1860], [2140, 1320]], dtype=float)\n",
    "source_points_4 = np.array([[2430, 2630], [1650, 1970], [300, 1920], [2790, 1670], [1620, 2150], [3080, 1220]], dtype=float)\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.imshow(image_four)\n",
    "plot_closed_polygon(source_points_4, color='red', label_prefix='b', show_labels=True)\n",
    "plt.show()\n",
    "\n",
    "# plt.figure(figsize=(18, 9))\n",
    "# plt.imshow(image_all)\n",
    "# plt.plot(target_points_1[:,0], target_points_1[:,1], color='red', linestyle='-', linewidth=1)\n",
    "# plt.plot(target_points_2[:,0], target_points_2[:,1], color='blue', linestyle='-', linewidth=1)\n",
    "# plt.plot(target_points_3[:,0], target_points_3[:, 1], color='green', linestyle='-', linewidth=1)\n",
    "# plt.plot(target_points_4[:,0], target_points_4[:,1], color='yellow', linestyle='-', linewidth=1)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8318e3e9",
   "metadata": {
    "id": "8318e3e9"
   },
   "source": [
    "#### c. Verschmelzen eines projektiv entzerrten Bildpaares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b79e8c5",
   "metadata": {
    "id": "8b79e8c5"
   },
   "outputs": [],
   "source": [
    "def calculate_weights(height, width):\n",
    "    \"\"\"\n",
    "    Calculates a weight map based on the distance from the center.\n",
    "    Weights are 1.0 at the center and 0.0 at the edges.\n",
    "\n",
    "    Args:\n",
    "        height (int): The height of the image (N).\n",
    "        width (int): The width of the image (M).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A (height, width) array with float weights.\n",
    "    \"\"\"\n",
    "    # Create coordinate grids\n",
    "    # M = width, N = height\n",
    "    i_coords, j_coords = np.meshgrid(np.arange(width), np.arange(height))\n",
    "\n",
    "    # Calculate weights using the formula\n",
    "    # Note: Use 2.0 and M/2.0 to ensure float division\n",
    "    w_i = 1.0 - (2.0 / width) * np.abs(i_coords - width / 2.0)\n",
    "    w_j = 1.0 - (2.0 / height) * np.abs(j_coords - height / 2.0)\n",
    "\n",
    "    # Combine weights and ensure they are >= 0 (due to float precision)\n",
    "    weights = np.maximum(0.0, w_i * w_j)\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230aed8a",
   "metadata": {
    "id": "230aed8a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def blend_images(img1_warped, weights1_warped, img2_warped, weights2_warped, mode='average'):\n",
    "    \"\"\"\n",
    "    Verschmilzt zwei transformierte Bilder anhand ihrer Gewichts-Maps. [cite: 5]\n",
    "    Diese Funktion ist eine überarbeitete Version, um Fehler zu beheben\n",
    "    und die Logik zu verdeutlichen.\n",
    "\n",
    "    Args:\n",
    "        img1_warped (np.ndarray): Das erste transformierte Bild (H, W, C oder H, W).\n",
    "        weights1_warped (np.ndarray): Die transformierte Gewichts-Map für das erste Bild (H, W).\n",
    "        img2_warped (np.ndarray): Das zweite transformierte Bild (H, W, C oder H, W).\n",
    "        weights2_warped (np.ndarray): Die transformierte Gewichts-Map für das zweite Bild (H, W).\n",
    "        mode (str): Der Modus: 'average' für gewichteten Mittelwert [cite: 10]\n",
    "                    oder 'max' für die Auswahl des Pixels mit dem höheren Gewicht. [cite: 10]\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Das verschmolzene Bild.\n",
    "    \"\"\"\n",
    "    # --- 1. Eingabeüberprüfung ---\n",
    "    if img1_warped.shape[:2] != weights1_warped.shape or \\\n",
    "       img2_warped.shape[:2] != weights2_warped.shape or \\\n",
    "       img1_warped.shape != img2_warped.shape:\n",
    "        raise ValueError(\"Die Dimensionen von Bildern und Gewichten müssen übereinstimmen.\")\n",
    "\n",
    "    # --- 2. Vorbereitung ---\n",
    "    # Konvertiere Bilder und Gewichte zu float für genaue Berechnungen\n",
    "    img1_f = img1_warped.astype(np.float32)\n",
    "    img2_f = img2_warped.astype(np.float32)\n",
    "    w1_2d = weights1_warped.astype(np.float32)\n",
    "    w2_2d = weights2_warped.astype(np.float32)\n",
    "\n",
    "    # Ein kleiner Wert, um Division durch Null zu vermeiden\n",
    "    epsilon = 1e-8\n",
    "\n",
    "    # --- 3. Blending-Logik ---\n",
    "    if mode == 'average':\n",
    "        w1 = w1_2d[..., np.newaxis]\n",
    "        w2 = w2_2d[..., np.newaxis]\n",
    "\n",
    "        w_sum = w1 + w2 + epsilon\n",
    "        blended_img = (img1_f * w1 + img2_f * w2) / w_sum\n",
    "\n",
    "    elif mode == 'max':\n",
    "        blended_img = np.zeros_like(img1_f)\n",
    "\n",
    "        # Erzeuge 3D-Masken (H,W,1) für RGB-Bilder\n",
    "        mask1 = (w1_2d >= w2_2d)[..., np.newaxis]\n",
    "        mask2 = (w2_2d > w1_2d)[..., np.newaxis]\n",
    "\n",
    "\n",
    "        blended_img = img1_f * mask1 + img2_f * mask2\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unbekannter Blending-Modus. Wähle 'average' oder 'max'.\")\n",
    "\n",
    "    # --- 4. Bereiche ohne Daten behandeln ---\n",
    "    # Erstelle eine Maske für Bereiche, in denen *beide* Gewichte nahe Null sind\n",
    "    no_data_mask = (w1_2d < epsilon) & (w2_2d < epsilon)\n",
    "    # Setze diese Bereiche im finalen Bild auf Schwarz (0)\n",
    "    blended_img[no_data_mask] = 0\n",
    "    \n",
    "    # --- 5. Rückgabe des verschmolzenen Bildes ---\n",
    "    return np.clip(blended_img, 0, 255).astype(img1_warped.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac987cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0ac987cc",
    "outputId": "598259a9-c3dd-4b56-9adb-dc294f86174b"
   },
   "outputs": [],
   "source": [
    "one_image_transformed = projective_transform(image_one, source_points_1, (2300, 4000), target_points_1)\n",
    "plt.imshow(one_image_transformed)\n",
    "plt.show()\n",
    "\n",
    "two_image_transformed = projective_transform(image_two, source_points_2, (2300, 4000), target_points_2)\n",
    "plt.imshow(two_image_transformed)\n",
    "plt.show()\n",
    "\n",
    "three_image_transformed = projective_transform(image_three, source_points_3, (2300, 4000), target_points_3)\n",
    "plt.imshow(three_image_transformed)\n",
    "plt.show()\n",
    "\n",
    "four_image_transformed = projective_transform(image_four, source_points_4, (2300, 4000), target_points_4)\n",
    "plt.imshow(four_image_transformed)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2446895",
   "metadata": {
    "id": "e2446895"
   },
   "outputs": [],
   "source": [
    "h_one_orig, w_one_orig = one_image_transformed.shape[:2]\n",
    "weights_one_orig = calculate_weights(h_one_orig, w_one_orig)\n",
    "H_one = compute_homography_least_squares(source_points_1, target_points_1)\n",
    "weights_transformed_one = cv2.warpPerspective(weights_one_orig, H_one, (4000, 2300))\n",
    "\n",
    "h_two_orig, w_two_orig = two_image_transformed.shape[:2]\n",
    "weights_two_orig = calculate_weights(h_two_orig, w_two_orig)\n",
    "H_two = compute_homography_least_squares(source_points_2, target_points_2)\n",
    "weights_transformed_two = cv2.warpPerspective(weights_two_orig, H_two, (4000, 2300))\n",
    "\n",
    "h_three_orig, w_three_orig = three_image_transformed.shape[:2]\n",
    "weights_three_orig = calculate_weights(h_three_orig, w_three_orig)\n",
    "H_three = compute_homography_least_squares(source_points_3, target_points_3)\n",
    "weights_transformed_three = cv2.warpPerspective(weights_three_orig, H_three, (4000, 2300))\n",
    "\n",
    "h_four_orig, w_four_orig = four_image_transformed.shape[:2]\n",
    "weights_four_orig = calculate_weights(h_four_orig, w_four_orig)\n",
    "H_four = compute_homography_least_squares(source_points_4, target_points_4)\n",
    "weights_transformed_four = cv2.warpPerspective(weights_four_orig, H_four, (4000, 2300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcabc94",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "3bcabc94",
    "outputId": "295fe82c-b1fb-4a80-e66b-eef3c3468aad"
   },
   "outputs": [],
   "source": [
    "blended_image_max = blend_images(three_image_transformed, weights_transformed_three, two_image_transformed, weights_transformed_two, mode='max')\n",
    "blended_image_ave = blend_images(three_image_transformed, weights_transformed_three, two_image_transformed, weights_transformed_two, mode='average')\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(blended_image_max)\n",
    "plt.title(\"Pixel mit dem größeren Gewicht\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(blended_image_ave)\n",
    "plt.title(\"gewichtetes Mittel aus allen Pixeln\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7542889a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "7542889a",
    "outputId": "da55eb9b-0209-465f-b057-6dc4b67b2e22"
   },
   "outputs": [],
   "source": [
    "blended_weights = weights_transformed_three + weights_transformed_two\n",
    "blended_blended_image_max = blend_images(blended_image_max, blended_weights, four_image_transformed, weights_transformed_four, mode='max')\n",
    "blended_blended_image_ave = blend_images(blended_image_ave, blended_weights, four_image_transformed, weights_transformed_four, mode='average')\n",
    "\n",
    "blended_all_weights = blended_weights + weights_transformed_four\n",
    "blended_all_image_max = blend_images(blended_blended_image_max, blended_all_weights, one_image_transformed, weights_transformed_one, mode='max')\n",
    "blended_all_image_ave = blend_images(blended_blended_image_ave, blended_all_weights, one_image_transformed, weights_transformed_one, mode='average')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))  \n",
    "\n",
    "plt.subplot(1, 2, 1) \n",
    "plt.imshow(blended_all_image_max)\n",
    "plt.title(\"Pixel mit dem größeren Gewicht\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2) \n",
    "plt.imshow(blended_all_image_ave)\n",
    "plt.title(\"gewichtetes Mittel aus allen Pixeln\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752f43f5",
   "metadata": {
    "id": "752f43f5"
   },
   "source": [
    "#### d. multi-band blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d49354",
   "metadata": {
    "id": "e3d49354"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 # Stellt sicher, dass OpenCV importiert ist\n",
    "\n",
    "def multi_band_blend(img1_warped, weights1_warped, img2_warped, weights2_warped):\n",
    "    \"\"\"\n",
    "    Verschmilzt zwei transformierte Bilder mittels Multi-Band Blending.\n",
    "    Diese korrigierte Version behebt den IndexError bei der Maskierung.\n",
    "\n",
    "    Args:\n",
    "        img1_warped (np.ndarray): Das erste transformierte Bild.\n",
    "        weights1_warped (np.ndarray): Die transformierte Gewichts-Map für das erste Bild (H, W).\n",
    "        img2_warped (np.ndarray): Das zweite transformierte Bild.\n",
    "        weights2_warped (np.ndarray): Die transformierte Gewichts-Map für das zweite Bild (H, W).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Das via Multi-Band Blending verschmolzene Bild.\n",
    "    \"\"\"\n",
    "    # --- 1. Eingabeüberprüfung ---\n",
    "    if img1_warped.shape[:2] != weights1_warped.shape or \\\n",
    "       img2_warped.shape[:2] != weights2_warped.shape or \\\n",
    "       img1_warped.shape != img2_warped.shape:\n",
    "        raise ValueError(\"Die Dimensionen von Bildern und Gewichten müssen übereinstimmen.\")\n",
    "\n",
    "    # --- 2. Vorbereitung ---\n",
    "    img1_f = img1_warped.astype(np.float32)\n",
    "    img2_f = img2_warped.astype(np.float32)\n",
    "    # Behalte 2D-Gewichte für Masken\n",
    "    w1_2d = weights1_warped.astype(np.float32)\n",
    "    w2_2d = weights2_warped.astype(np.float32)\n",
    "    epsilon = 1e-8\n",
    "\n",
    "    # --- 3. Zerlegung ---\n",
    "    # Verwende Gauß-Filter für den Tiefpass [cite: 21]\n",
    "    kernel_size_tuple = (201, 201)\n",
    "    sigma_val = 20\n",
    "    low1 = cv2.GaussianBlur(img1_f, kernel_size_tuple, sigma_val)\n",
    "    low2 = cv2.GaussianBlur(img2_f, kernel_size_tuple, sigma_val)\n",
    "    # Erhalte Hochpass durch Subtraktion [cite: 22]\n",
    "    high1 = img1_f - low1\n",
    "    high2 = img2_f - low2\n",
    "\n",
    "    # --- 4. Tiefpass-Blending (Gewichteter Mittelwert) --- [cite: 13]\n",
    "    # Erweitere Gewichte nur für die Mittelwert-Berechnung\n",
    "    w1_bc = w1_2d[..., np.newaxis]\n",
    "    w2_bc = w2_2d[..., np.newaxis]\n",
    "    w_sum = w1_bc + w2_bc + epsilon\n",
    "    blended_low = (low1 * w1_bc + low2 * w2_bc) / w_sum\n",
    "\n",
    "    # --- 5. Hochpass-Blending (Maximales Gewicht) --- [cite: 13]\n",
    "    blended_high = np.zeros_like(img1_f)\n",
    "    # Erstelle 2D-Masken (H, W) aus den 2D-Gewichten\n",
    "    mask_w1_ge_w2 = (w1_2d >= w2_2d)\n",
    "    mask_w2_gt_w1 = (w2_2d > w1_2d)\n",
    "\n",
    "    # Wende die 2D-Masken auf die 3D-Hochpassbilder an\n",
    "    mask1 = mask_w1_ge_w2[..., np.newaxis]\n",
    "    mask2 = mask_w2_gt_w1[..., np.newaxis]\n",
    "\n",
    "    blended_high = high1 * mask1 + high2 * mask2\n",
    "\n",
    "\n",
    "    # --- 6. Rekonstruktion ---\n",
    "    blended_img = blended_low + blended_high\n",
    "\n",
    "    # --- 7. Bereiche ohne Daten behandeln ---\n",
    "    # Erstelle eine 2D-Maske für Bereiche, wo beide Gewichte Null sind\n",
    "    no_data_mask = (w1_2d < epsilon) & (w2_2d < epsilon)\n",
    "    # Wende die 2D-Maske an, um diese Bereiche auf Schwarz zu setzen\n",
    "    blended_img[no_data_mask] = 0\n",
    "\n",
    "    # --- 8. Finale Konvertierung ---\n",
    "    return np.clip(blended_img, 0, 255).astype(img1_warped.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b95277a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "id": "4b95277a",
    "outputId": "f0ddccdb-798e-427c-eba2-bbaef643dd28"
   },
   "outputs": [],
   "source": [
    "multi_blended_image = multi_band_blend(three_image_transformed, weights_transformed_three, two_image_transformed, weights_transformed_two)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(multi_blended_image)\n",
    "plt.title(\"multi band\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(blended_image_ave)\n",
    "plt.title(\"gewichtetes Mittel aus allen Pixeln\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7bbacd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 802
    },
    "id": "2f7bbacd",
    "outputId": "2a95e195-3d5b-4c93-9b92-9ef3cf4c1f0d"
   },
   "outputs": [],
   "source": [
    "\n",
    "multi_blended_blended_image = multi_band_blend(multi_blended_image, blended_weights, four_image_transformed, weights_transformed_four)\n",
    "multi_blended_all_image = multi_band_blend(multi_blended_blended_image, blended_all_weights, one_image_transformed, weights_transformed_one)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(blended_all_image_max)\n",
    "plt.title(\"Gewichtung Max\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(blended_all_image_ave)\n",
    "plt.title(\"gewichtetes Mittel aus allen Pixeln\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(multi_blended_all_image)\n",
    "plt.title(\"Multi Band Blending\")\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
